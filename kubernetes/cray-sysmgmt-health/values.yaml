#
# MIT License
#
# (C) Copyright 2021-2022 Hewlett Packard Enterprise Development LP
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
# ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.
#
global:
  authGateway: services/services-gateway
  rbac:
    create: true
    pspEnabled: true

kubectl:
  image:
    repository: artifactory.algol60.net/csm-docker/stable/docker-kubectl
    tag: 1.19.15
    pullPolicy: IfNotPresent

# Enable/Disable subcharts
# grafana:
#   enabled: true
# kubeStateMetrics:
#   enabled: false
# nodeExporter:
#   enabled: true

prometheus-snmp-exporter:
  image:
    repository: artifactory.algol60.net/csm-docker/stable/docker.io/prom/snmp-exporter
    tag: v0.20.0
    pullPolicy: IfNotPresent

  serviceMonitor:
    enabled: true
    namespace: sysmgmt-health
    selector:
      prometheus: cray-sysmgmt-health-promet-prometheus
      release: cray-sysmgmt-health

    params:
      enabled: false
      conf:
        module:
        - if_mib
        target:
        - 127.0.0.1

prometheus-operator:


  prometheusOperator:
    admissionWebhooks:
      patch:
        enabled: true
        image:
          repository: artifactory.algol60.net/csm-docker/stable/docker.io/jettech/kube-webhook-certgen
          tag: v1.2.1
          pullPolicy: IfNotPresent

    image:
      repository: artifactory.algol60.net/csm-docker/stable/quay.io/coreos/prometheus-operator
      tag: v0.38.1
      pullPolicy: IfNotPresent

    prometheusConfigReloaderImage:
      repository: artifactory.algol60.net/csm-docker/stable/quay.io/coreos/prometheus-config-reloader
      tag: v0.38.1

    # Resources for config-reloader side car, these are the same for requests and limits.
    # configReloaderCpu: 100m (default)
    # configReloaderMemory: 100m (default)
    configReloaderCpu: 300m

    tlsProxy:
      image:
        repository: artifactory.algol60.net/csm-docker/stable/docker.io/ghostunnel/ghostunnel
        tag: v1.6.0

    configmapReloadImage:
      repository: artifactory.algol60.net/csm-docker/stable/docker.io/jimmidyson/configmap-reload

  prometheus:
    prometheusSpec:

      image:
        repository: artifactory.algol60.net/csm-docker/stable/quay.io/prometheus/prometheus
        tag: v2.18.1

      # Enable administrative HTTP API, 'cause why not?
      enableAdminAPI: true

      # Configure external hostname for Istio ingress
      # externalAuthority: prometheus-kube.local
      # externalUrl: https://prometheus-kube.local/

      secrets:
        # Client certificate in order to scrape Etcd (see kubeEtcd below)
        - etcd-client-cert

      # Adjust retention period consistent with provisioned storage (see next)
      retention: 48h

      # Configure persistent storage for Prometheus instances.
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 200Gi

      # Managed as per environment basis
      # resources:
      #   limits:
      #     cpu: '3'
      #     memory: 12Gi
      #   requests:
      #     cpu: '1'
      #     memory: 9Gi

      ruleSelector:
        matchLabels:
          release: cray-sysmgmt-health

      additionalScrapeConfigs:
        # Scrape containerd metrics
        - job_name: 'containerd'
          metrics_path: '/v1/metrics'
          kubernetes_sd_configs:
          - role: node
          relabel_configs:
          # Add node labels
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          # Set "node" label
          - source_labels: [__meta_kubernetes_node_name]
            action: replace
            target_label: node
          # Replace the default service port
          - source_labels: [__address__]
            action: replace
            target_label: __address__
            regex: ^(.+?)(?::\d+)?$
            replacement: $1:1338

        # Scrape weave metrics
        - job_name: 'weave'
          kubernetes_sd_configs:
          - api_server:
            role: pod
          relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_name]
            action: keep
            regex: ^kube-system;weave-net$
          - source_labels: [__meta_kubernetes_pod_container_name, __address__]
            action: replace
            target_label: __address__
            regex: ^weave;(.+?)(?::\d+)?$
            replacement: $1:6782
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: drop
            regex: ^weave-init$
          - source_labels: [__meta_kubernetes_pod_container_name, __address__]
            action: replace
            target_label: __address__
            regex: ^weave-npc;(.+?)(?::\d+)?$
            replacement: $1:6781
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: job

        # Federate metrics from Istio's Prometheus instance
        # - job_name: 'federate-istio'
        #   scrape_timeout: 45s
        #   scrape_interval: 1m
        #   honor_labels: true
        #   metrics_path: '/federate'
        #   params:
        #     'match[]':
        #       - '{__name__=~".+"}'
        #   static_configs:
        #     - targets:
        #       - 'prometheus.istio-system:9090'

        # Federate metrics from Ceph's Prometheus instance
        # - job_name: 'federate-ceph'
        #   scrape_timeout: 45s
        #   scrape_interval: 1m
        #   honor_labels: true
        #   metrics_path: '/federate'
        #   params:
        #     'match[]':
        #       - '{__name__=~".+"}'
        #   static_configs:
        #     - targets:
        #       - 'cray-ceph-monitoring-prometheus.ceph-monitoring:9090'

  alertmanager:

    alertmanagerSpec:
      image:
        repository: artifactory.algol60.net/csm-docker/stable/quay.io/prometheus/alertmanager

      # Adjust retention period consistent with provisioned storage (see next)
      retention: 48h
      # Configure storage for alertmanager instances
      storage:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 50Gi

      resources:
        requests:
          cpu: 100m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi

      # Configure external hostname for Istio ingress
      # Setup with Ansible
      # externalAuthority: alertmanager-shs.local
      # externalUrl: https://alertmanager-shs.local/

  grafana:

    image:
      repository: artifactory.algol60.net/csm-docker/stable/docker.io/grafana/grafana
      tag: 7.0.3

    # Configure external hostname for Istio ingress
    # Setup with Ansible
    # externalAuthority: grafana-shs.local

    # Note: We are using our own templates while OPA-istio-plugin is fixed CASMPET-2788
    defaultDashboardsEnabled: false

    # persistence:
    #  enabled: true
    #  size: 100Gi

    # Change default admin password to be consistent. Although with the
    # auth.proxy configured below, this won't normally matter.
    adminUser: admin
    adminPassword: admin

    # Grafana's primary configuration
    grafana.ini:
      analytics:
        check_for_updates: false
      # External authentication provided by Keycloak Gatekeeper and
      # external authorization by OPA (enforced by Istio).
      auth.proxy:
        enabled: true
        header_name: X-WEBAUTH-USER
        header_property: username
        auto_sign_up: true

    sidecar:
      image:
        repository: artifactory.algol60.net/csm-docker/stable/docker.io/kiwigrid/k8s-sidecar
        tag: 0.1.151
      dashboards:
        enabled: true
      datasources:
        enabled: true
        defaultDatasourceEnabled: true

    # vonage-status-panel in upstream is broken and we need to install latest stable version from fork until is merged
    plugins:
    - grafana-piechart-panel
    - https://github.com/MefhigosetH/Grafana_Status_panel/archive/hotfix/issue-159.zip;vonage-status-panel

    datasources:
      datasources.yaml:
        apiVersion: 1
        datasources:
        - name: istio-monitoring
          type: prometheus
          url: http://cray-sysmgmt-health-promet-prometheus:9090
          access: proxy

    testFramework:
      image: artifactory.algol60.net/csm-docker/stable/docker.io/bats/bats

  # Exporters
  kubelet:
    enabled: true
    serviceMonitor:
      https: true
      cAdvisor: true
      probes: true
      resource: true
      resourcePath: "/metrics/resource"

  kubeControllerManager:
    service:
      https: true
      port: 10257
      targetPort: 10257
    serviceMonitor:
      https: true
      insecureSkipVerify: true

  kubeScheduler:
    service:
      https: true
      port: 10259
      targetPort: 10259
    serviceMonitor:
      https: true
      insecureSkipVerify: true

  kubeEtcd:
    # Configure secure access to the etcd cluster via the key and certs
    # defined in the `etcd-client-cert` secret (see below).
    serviceMonitor:
      interval: ""
      scheme: https
      insecureSkipVerify: false
      serverName: ""
      caFile: "/etc/prometheus/secrets/etcd-client-cert/etcd-ca"
      certFile: "/etc/prometheus/secrets/etcd-client-cert/etcd-client"
      keyFile: "/etc/prometheus/secrets/etcd-client-cert/etcd-client-key"

  prometheus-node-exporter:

    image:
      repository: artifactory.algol60.net/csm-docker/stable/quay.io/prometheus/node-exporter
      tag: v1.2.2
    resources:
      limits:
        cpu: "6"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 1Gi
    extraArgs:
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run|var\/lib\/containerd.+|run/.+)($|/)  # containerd puts container fs's in /run/containerd/
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      - --no-collector.netclass
      - --collector.buddyinfo
      - --collector.drbd
      - --collector.interrupts
      - --collector.ksmd
      - --collector.logind
      - --collector.meminfo_numa
      - --collector.mountstats
      - --collector.processes
      - --collector.systemd
      # tcpstat has potential performance impact
      - --collector.tcpstat
      - --collector.textfile.directory=/var/lib/node_exporter
    extraHostVolumeMounts:
      - mountPath: /var/run/dbus/system_bus_socket
        name: system-dbus-socket
        readOnly: true
        hostPath: /var/run/dbus/system_bus_socket
      - mountPath: /var/lib/containerd
        name: containerd
        readOnly: true
        hostPath: /var/lib/containerd
      - mountPath: /var/lib/kubelet
        name: kubelet
        readOnly: true
        hostPath: /var/lib/kubelet
      - name: text-file-collector
        hostPath: /var/lib/node_exporter
        mountPath: /var/lib/node_exporter
        readOnly: true
        mountPropagation: HostToContainer

  # Compatibility with dashboards and rules templates
  kube-state-metrics:
    image:
      repository: artifactory.algol60.net/csm-docker/stable/quay.io/coreos/kube-state-metrics
      tag: v1.9.7

  kubeStateMetrics:
    enabled: true


customRules:
  create: true
  rules:
    ceph: true
    postgresql: true
    mdraid: true
    kea-dhcp-alerts: true
    smartmon-alerts: true
    istio-alerts: true
  labels:
    release: cray-sysmgmt-health
  ## Annotations for default rules
  annotations: {}


customDashboards:
  ceph:
    enabled: true
  postgresql:
    enabled: true
  istio:
    enabled: true
    galley:
      enabled: true
    pilot:
      enabled: true
  nodeExporter:
    enabled: true
  dhcp_kea:
    enabled: true
  unbounddns:
    enabled: true
  # Note: We are using our own templates while OPA-istio-plugin is fixed CASMPET-2788
  prometheusOperator:
    enabled: true
# coreDns:
#   enabled: true
# kubeApiServer:
#   enabled: true
# kubeControllerManager:
#   enabled: true
# kubeDns:
#   enabled: true
# kubeEtcd:
#   enabled: true
# kubeProxy:
#   enabled: true
# kubeScheduler:
#   enabled: true
# kubeStateMetrics:
#   enabled: true
# kubelet:
#   enabled: true

# prometheusOperator:
#   enabled: true
#   kubeletService:
#     enabled: true

cephExporter:
  enabled: true
  endpoints: []
  service:
    port: 9283
    targetPort: 9283
  serviceMonitor:
    interval: 30s
    scheme: http
    # honor_labels: true
    # serverName: ""
    # caFile: ""
    # certFile: ""
    # keyFile: ""
    insecureSkipVerify: false
    metricsRelabelings: {}
    relabelings: {}

cephNodeExporter:
  enabled: true
  endpoints: []
  service:
    port: 9100
    targetPort: 9100
  serviceMonitor:
    interval: 30s
    scheme: http
    # honor_labels: false
    # serverName: ""
    # caFile: ""
    # certFile: ""
    # keyFile: ""
    insecureSkipVerify: false
    metricsRelabelings: {}
    relabelings: {}

rmPalsPostgresExporter:
  enabled: true
  service:
    namespace: services
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: cray-rm-pals-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

slsPostgresExporter:
  enabled: true
  service:
    namespace: services
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: cray-sls-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

smdPostgresExporter:
  enabled: true
  service:
    namespace: services
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: cray-smd-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

giteaVcsPostgresExporter:
  enabled: true
  service:
    namespace: services
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: gitea-vcs-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

keycloakPostgresExporter:
  enabled: true
  service:
    namespace: services
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: keycloak-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

smaPostgresExporter:
  enabled: true
  service:
    namespace: sma
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: sma-postgres-cluster
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - sma
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

spirePostgresExporter:
  enabled: true
  service:
    namespace: spire
    port: 9187
    targetPort: 9187
    selector:
      cluster-name: spire-postgres
      application: spilo
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - spire
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

dhcpKeaExporter:
  enabled: true
  service:
    namespace: services
    port: 8080
    targetPort: 8080
    selector:
      app.kubernetes.io/name: cray-dhcp-kea
  serviceMonitor:
    namespace: sysmgmt-health
    matchNamespace:
    - services
    interval: 30s
    scheme: http
    port: exporter
    metricsRelabelings: {}
    relabelings: {}

servicemonitors:
  bosEtcdExporter:
    enabled: true
    servicename: bos
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-bos-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  bssEtcdExporter:
    enabled: true
    servicename: bss
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-bss-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  cpsEtcdExporter:
    enabled: true
    servicename: cps
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-cps-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  crusEtcdExporter:
    enabled: true
    servicename: crus
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-crus-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  externaldnsEtcdExporter:
    enabled: true
    servicename: externaldns
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-externaldns-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  fasEtcdExporter:
    enabled: true
    servicename: fas
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-fas-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  hbtdEtcdExporter:
    enabled: true
    servicename: hbtd
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-hbtd-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  redsEtcdExporter:
    enabled: true
    servicename: reds
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-reds-etcd
      interval: 30s
      scheme: http
      port: http-client
      metricsRelabelings: {}
      relabelings: {}

  hmnfdEtcdExporter:
    enabled: true
    servicename: hmnfd
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-hmnfd-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

  uasMgrEtcdExporter:
    enabled: true
    servicename: uas-mgr
    cluster: etcd
    serviceMonitor:
      namespace: sysmgmt-health
      port: http-client
      matchNamespace:
      - services
      matchLabels:
        etcd_cluster: cray-uas-mgr-etcd
      interval: 30s
      scheme: http
      metricsRelabelings: {}
      relabelings: {}

grafterm:
  image:
    repository: artifactory.algol60.net/csm-docker/stable/cray-grafterm
    tag: 1.0.1
    pullPolicy: IfNotPresent
  dashboards:
    enabled: true

smartmetrics:
  enabled: true
  image:
    repository: artifactory.algol60.net/csm-docker/stable/quay.io/galexrt/node-exporter-smartmon
    tag: v0.1.1
    pullPolicy: IfNotPresent
